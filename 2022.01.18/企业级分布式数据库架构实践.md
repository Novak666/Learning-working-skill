企业级分布式数据库架构实践

# 1. 概述

大型网站的系统架构并不是从一开始就具备高性能、高可用、高伸缩等特性的。小型创业公司通常不需要设计非常复杂的系统架构，能将基本的业务跑起来就行。

随着用户和业务量的增加，系统架构需要根据具体情况重新设计，这其中就包括容易出现瓶颈的数据库服务器。

针对数据库架构的优化要根据业务特点、以及实施的成本逐步进行，通常不会一上来就设计出一个非常复杂的架构。

数据库的优化可以从这些方面进行

- SQL 优化
- 索引优化
- 缓存系统
- 主从复制、读写分离
- 垂直拆分
- 水平拆分

# 2. 数据库扩展思想

- 热备

  > 在数据库服务器运行过程中对数据进行备份操作。相对的是冷备，冷备份需要停机操作。

- 多活

  > 多个数据库服务器，保证高可用，避免单点故障。

- 故障切换

  > 当一台数据库服务器出现异常，自动切换到其他数据库服务器继续提供服务。

- 读写分离

  > 数据库的读写操作分发到不同的服务器，提高数据处理能力。

- 负载均衡

  > 负载均衡一般是建立的读写分离的基础之上，将读写操作根据情况，合理的分摊到数据库服务器，提高并发能力，同时避免过载。

# 3. 主从复制

## 3.1 概述

主从复制，是通过部署多台数据库服务器，这些数据库之间有主从关系。其中，主数据库用于提供服务，从数据库中的数据和主数据库是保持一致的，这样做的好处是能够热备份，同时，可以在此基础上扩展读写分离的架构。

主从复制的架构一般分为：一主一从、一主多从、主主复制、级联复制、主主与级联复制的结合。

![1](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/1.png)

这是一个典型的一主多从读写分离架构，应用系统写数据时，会写入到 master  节点，然后再由 master 节点将数据复制到 slave 节点中。这个架构仍有不足，例如 master 节点存在单点、数据的复制存在延迟。

## 3.2 单主单从

演示单主单从的主从复制

1、在 Docker 中创建两个数据库容器

```shell
# 创建数据库容器挂载目录
mkdir -p /usr/local/mysql/3306/conf
mkdir -p /usr/local/mysql/3306/data
mkdir -p /usr/local/mysql/3307/conf
mkdir -p /usr/local/mysql/3307/data

# 创建一个临时容器
docker run -d --name temp -e MYSQL_ROOT_PASSWORD=123456 mysql:5.5

# 复制配置文件
docker cp temp:/etc/mysql/my.cnf /usr/local/mysql/3306/conf/my.cnf
docker cp temp:/etc/mysql/my.cnf /usr/local/mysql/3307/conf/my.cnf

# 删除临时容器
docker rm -f temp

##################################

# 创建容器
docker run -d --name master3306 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /usr/local/mysql/3306/conf/my.cnf:/etc/mysql/my.cnf -v /usr/local/mysql/3306/data/:/var/lib/mysql/ mysql:5.5 --character-set-server=utf8
docker run -d --name slave3307 -p 3307:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /usr/local/mysql/3307/conf/my.cnf:/etc/mysql/my.cnf -v /usr/local/mysql/3307/data/:/var/lib/mysql/ mysql:5.5 --character-set-server=utf8
```

2、修改配置文件，添加内容

`3306/conf/my.cnf`

```properties
server-id=1
log-bin=binlog
binlog-do-db=company
binlog-ignore-db=mysql
binlog-ignore-db=information_schema
binlog-ignore-db=performance_schema
binlog-format=STATEMENT
```

`3307/conf/my.cnf`

```properties
server-id=2
relay-log=relaylog
replicate-do-db=company
replicate-ignore-db=mysql
replicate-ignore-db=information_schema
replicate-ignore-db=performance_schema
```

3、重启 master 和 slave

```shell
docker restart master3306
docker restart slave3307
```

4、在 master 上创建用户并授权

```sql
-- 创建用户
create user 'slave'@'172.17.0.3' identified by '123456';

-- 授权
grant all privileges on *.* to 'slave'@'172.17.0.3' with grant option;

-- 刷新权限
flush privileges;
```

5、查看 master 状态信息

```sql
show master status;
```

![2](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/2.png)

6、在 slave 上更新 master 的信息

```sql
-- 关闭 slave
stop slave;

-- 更新 master 的信息
change master to master_host='172.17.0.2',master_user='slave',master_password='123456',master_log_file='binlog.000001',master_log_pos=440;

-- 开启 slave
start slave;

-- 查看 slave 信息
show slave status\G;
```

![3](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/3.png)

IO Thread 和 SQL Thread 都处于正常运行状态，表示 slave 已准备就绪。

7、测试

- 在 master 中创建数据库、数据表、插入数据，slave 会同步
- 但在 slave 中插入数据，不会同步到 master 中，因为现在是单向的。

## 3.3 主从复制的原理

在 MySQL 中有两种复制机制，分别是异步复制和半同步复制，默认情况下采用的是异步复制。

异步复制

![4](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/4.png)

流程

1. 应用程序提交事务到 master
2. master 收到事务的提交请求后，会更新内部的 binlog 日志，接着让 mysql 引擎执行事务操作，并返回给客户端执行结果。同时，master 中还有一个事件监听，监听着 binlog 日志的变化，一旦发生更新，则会触发 dump 线程。
3. dump 线程被触发后，通知 slave 中的 I/O 线程。
4. slave 中的 I/O 线程收到通知后，会从 relay-log.info 文件中获取 binlog 日志文件和 pos 位置信息，并发送给 master 的 dump 线程。
5. master 的 dump 线程收到信息后，会将日志文件的 pos 位置之后的所有日志都同步给 slave 的 I/O 线程。
6. slave 的 I/O 线程接受到同步过来的日志后，会将日志记录到 relaybin 中继日志中。
7. SQL 线程监听到 relaybin 发生更改，会将新的日志读取出来并重做数据【异步操作】
8. slave 将日志记录到 relaybin 之后，会返回一个 ACK 消息给 master。

对于这一系列的操作，可以发现 master 写入完 binlog 后，会立即提交事务并向客户端返回响应，而对于数据的同步，则是以异步的形式完成的。

这种方式的优点的响应速度快，缺点是可能会造成数据不一致（存在延迟）。

## 3.4 半同步复制

![5](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/5.png)

半同步复制和异步复制的工作流程大体相同，不同的是，master 在写入 binlog 日志之后，不会立即通过引擎提交事务，而是暂时挂起等待，等 slave 响应的 ACK 之后，再唤醒等待，继续执行。

半同步复制的优点是保证数据的一致性，但性能会降低。

注意：半同步复制时如果等待没有被唤醒，它不会一直等待下去，默认的等待时间是10秒钟，但该时间是可以配置的。10秒钟过后，会自动唤醒并提交事务，同时自动的切换到异步复制，待 slave 节点恢复后又会重新切换到半同步复制。

## 3.5 主从复制相关文件介绍

master 节点

![6](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/6.png)

执行过的更新都记录在这些日志文件中。

slave 节点

![7](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/7.png)

## 3.6 异步复制演示

关闭 slave 节点，向 master 发送数据更改，能够立即得到响应，说明 master 不会等待 slave 的 ACK 确认。

## 3.7 半同步复制演示

配置

1、进入 master 容器，安装半同步复制插件。

```
install plugin rpl_semi_sync_master soname 'semisync_master.so';
```

2、查看插件信息

```
show plugins;
```

![8](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/8.png)

3、启用插件并设置等待超时时间

```
set global rpl_semi_sync_master_enabled=1; #1：启用，0：禁止
set global rpl_semi_sync_master_timeout=10000; #单位是毫秒
```

插件启用成功后，master 会打印相应的日志信息

![9](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/9.png)

4、进入 slave 容器安装半同步插件

```sql
install plugin rpl_semi_sync_slave soname 'semisync_slave.so';
```

5、启用 slave 的半同步插件

```sql
set global rpl_semi_sync_slave_enabled=1; #1：启用，0：禁止
```

6、重启 slave 的 I/O Thread

```sql
stop slave io_thread;
start slave io_thread;
```

7、到目前为止，半同步复制以及配置完成，可以在 master 中查看半同步复制的状态

```sql
-- 查询状态信息
show global status like "%sync%";

-- 查询参数信息
show global variables like '%sync%';
```

![10](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/10.png)

![11](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/11.png)

8、演示

模拟 slave 故障，主动关闭 slave 的 I/O 线程

```
stop slave io_thread;
```

在 master 节点更新数据，此时，master 10秒钟后才返回响应，说明半同步复制配置成功。

![12](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/12.png)

注意：再次更新数据不会等待10秒，因为已经自动切换到了异步复制

![13](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/13.png)

## 3.8 主主复制

前面我们演示的主从复制，只有一台 master 和一台 slave，此时 master 是存在单点问题的，一旦 master 宕机，则无法继续更新数据。

我们可以使用主主复制的方式来解决单点问题。

在主主复制的架构中，有两台 master，他们之间形成互备，两台 master 会进行相互复制。

![14](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/14.png)

现在，假设负责写数据的 master 宕机了，那么写数据的工作就交给之前负责读数据的服务器来完成，即负责写又负责读，避免单点故障。

这种架构的缺点是不能承载过高的读请求，因为相当于只有一台服务器负责读，所以应用的比较少。

搭建

1、创建两个 master 容器

```shell
# 创建数据库容器挂载目录
mkdir -p /usr/local/mysql/3308/conf
mkdir -p /usr/local/mysql/3308/data
mkdir -p /usr/local/mysql/3309/conf
mkdir -p /usr/local/mysql/3309/data

# 创建一个临时容器
docker run -d --name temp -e MYSQL_ROOT_PASSWORD=123456 mysql:5.5

# 复制配置文件
docker cp temp:/etc/mysql/my.cnf /usr/local/mysql/3308/conf/my.cnf
docker cp temp:/etc/mysql/my.cnf /usr/local/mysql/3309/conf/my.cnf

# 删除临时容器
docker rm -f temp

##################################

# 创建容器
docker run -d --name master3308 -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /usr/local/mysql/3308/conf/my.cnf:/etc/mysql/my.cnf -v /usr/local/mysql/3308/data/:/var/lib/mysql/ mysql:5.5 --character-set-server=utf8
docker run -d --name master3309 -p 3309:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /usr/local/mysql/3309/conf/my.cnf:/etc/mysql/my.cnf -v /usr/local/mysql/3309/data/:/var/lib/mysql/ mysql:5.5 --character-set-server=utf8
```

2、修改配置文件，添加内容

`3308/conf/my.cnf`

```properties
server-id=1
log-bin=binlog
binlog-do-db=company
binlog-ignore-db=mysql
binlog-ignore-db=information_schema
binlog-ignore-db=performance_schema
binlog-format=STATEMENT
relay-log=relaylog
```

`3309/conf/my.cnf`

```properties
server-id=2
log-bin=binlog
binlog-do-db=company
binlog-ignore-db=mysql
binlog-ignore-db=information_schema
binlog-ignore-db=performance_schema
binlog-format=STATEMENT
relay-log=relaylog
```

3、重启两台 master 服务器

```
docker restart master3308
docker restart master3309
```

4、为两台 master 创建账户并授权

```sql
-- master3308
create user 'master'@'172.17.0.3' identified by '123456';
grant all privileges on *.* to 'master'@'172.17.0.3' with grant option;
flush privileges;

-- master3309
create user 'master'@'172.17.0.2' identified by '123456';
grant all privileges on *.* to 'master'@'172.17.0.2' with grant option;
flush privileges;
```

5、更新 master 信息

```sql
-- master3308
stop slave;
change master to master_host='172.17.0.3',master_user='master',master_password='123456',master_log_file='binlog.000001',master_log_pos=434;
start slave;
show slave status;

-- master3309
stop slave;
change master to master_host='172.17.0.2',master_user='master',master_password='123456',master_log_file='binlog.000001',master_log_pos=434;
start slave;
show slave status;
```

6、测试

- master3308 创建数据库和表
- master3309 插入数据

观察两台 master 是否能相互复制。

## 3.9 级联复制

要想提高读的并发能力，并且还要减少主从复制带来的性能损耗，可以采用级联复制的架构。

![15](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/15.png)

级联复制的写请求入口仍然只有一个，但当 master 向 slave 进行复制时，对于 slave 可以分为多层，master 只需要向其中两台 slave 复制即可，然后再由这两台 slave 复制给更多的 slave。

通过这种方式能够有效的减低主从复制带来的性能损耗，但同时也会进一步增大延迟。

搭建slave要添加这个配置

```
log-slave-updates
```

完整的 slave 配置

```
server-id=1
log-bin=binlog
binlog-do-db=company
binlog-ignore-db=mysql
binlog-ignore-db=information_schema
binlog-ignore-db=performance_schema
binlog-format=STATEMENT
log-slave-updates
relay-log=relaylog
```

## 3.10 双主与级联复制结合

双主与级联复制架构在兼顾性能的同时，提高了系统的可用性。

![16](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/16.png)

## 3.11 小结

没有完美的架构，不同的主从复制架构各有优缺点，在工作中我们要根据实际情况，选择合适的架构。

# 4. 高可用实践

## 4.1 概述

以主主复制架构为例，如果其中一台 master 宕机，所有的读写请求将会交给另一台服务器承载，那么这里就涉及到一个 IP 指向的问题。同时，这种服务器的 IP 切换，对上层应用来说，应该是无感的。

这样的需求，我们可以通过 Keepalived 来完成 IP 的自动切换。

![17](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/17.png)

Keepalived 会在多台服务器中安装，同时，Keepalived 之间也分为主备，Master Keepalived 会虚拟化一个 IP 给应用程序进行连接，一旦 Master Keepalived 故障，Backup Keepalived 会立即接替 Master Keepalived 的工作，继续提供虚拟 IP 服务。

## 4.2 搭建 Keepalived

1、下载安装 Keepalived

下载地址：http://www.keepalived.org/download.html

2、安装依赖包

```
yum install -y psmisc

yum install -y openssl-devel gcc gcc-c++
```

3、安装

将解压后的 Keepalived 拷贝到 `/usr/local/keepalived` 目录

进入目录，配置并编译安装

```
./configure && make && make install
```

4、创建启动文件

```
cp -a /usr/local/etc/keepalived  /etc/init.d/
cp -a /usr/local/etc/sysconfig/keepalived  /etc/sysconfig/
cp -a /usr/local/sbin/keepalived  /usr/sbin/
```

5、编写 shell 脚本

创建 `/etc/keepalived` 目录，创建 `chk.sh` 脚本文件，并赋予权限

```shell
# 创建目录
mkdir /etc/keepalived

# 创建文件
touch chk.sh

# 赋予权限
chmod +x 
```

编写脚本，该脚本的作用是检测 MySQL 的状态（`需要安装 MySQL 客户端`）

```shell
#! /bin/bash
mysql -h 192.168.100.136 -u root -p123456 -P 3306 -e "show status;" >/dev/null 2>&1
if [ $? == 0 ]
then
    echo " $host mysql login successfully "
    exit 0
else
    echo "  mysql login faild"
    killall keepalived
    exit 2
fi
```

6、编写 Keepalived 配置文件

进到 `/etc/keepalived` 目录，编辑 `keepalived.conf` 文件

```
! Configuration File for keepalived
#简单的头部，这里主要可以做邮件通知报警等的设置，此处就暂不配置了；
global_defs {
    #notificationd LVS_DEVEL
    router_id MYSQL_4
    script_user root
    enable_script_security
}

#预先定义一个脚本，方便后面调用，也可以定义多个，方便选择；
vrrp_script chk_haproxy {
    script "/etc/keepalived/chk.sh"
    interval 2  #脚本循环运行间隔
}

#VRRP虚拟路由冗余协议配置
vrrp_instance VI_1 {     #VI_1 是自定义的名称；
    state MASTER         #MASTER表示是一台主设备，BACKUP表示为备用设备【我们这里因为设置为开启不抢占，所以都设置为备用】
    nopreempt            #开启不抢占
    interface ens33      #指定VIP需要绑定的物理网卡
    virtual_router_id 11 #VRID虚拟路由标识，也叫做分组名称，该组内的设备需要相同
    priority 100         #定义这台设备的优先级 1-254；开启了不抢占，所以此处优先级必须高于另一台

    advert_int 1         #生存检测时的组播信息发送间隔，组内一致
    authentication {     #设置验证信息，组内一致
        auth_type PASS   #有PASS 和 AH 两种，常用 PASS
        auth_pass 111111 #密码
    }
    virtual_ipaddress {
        192.168.100.200  #指定VIP地址，组内一致，可以设置多个IP
    }
    track_script {       #使用在这个域中使用预先定义的脚本，上面定义的
        chk_haproxy
    }
}
```

7、启动

```
systemctl start keepalived
```

8、查看虚拟 IP

![18](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/18.png)

9、测试

- 使用虚拟 IP 连接数据库
- 关闭 Master Keepalived，测试 Backup Keepalived 能否继续提供虚拟 IP 服务。

# 5. 数据切分核心思想

## 5.1 概述

在业务系统的开发过程中，很难预料到今后的用户量和数据量，所以，通常一个系统的早期架构可能是比较简单的。

随着用户和数据量的激增，单体数据库就会出现一定的性能瓶颈，此时，我们可以对数据库进行拆分。

## 5.2 垂直拆分

垂直拆分是按照业务将表进行分类，并分布到不同的数据节点上。

![19](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/19.png)

优点：

- 拆分规则明确，按照不同的功能模块或服务，拆分成多个数据库
- 数据维护简单

缺点：

- 对读写极其频繁且数据量超大的表，仍然存在存储与性能瓶颈
- 会出现跨库 join
- 需要对代码进行重构，修改原有的事务操作
- 某个表的数量达到一定程度后扩展比较困难

## 5.3 水平拆分

垂直拆分能够解决一部分问题，但仍然无法解决单表数据量过多引起的性能瓶颈，此时，我们可以使用水平拆分继续横向扩展。

将一张数据表拆成多张表，将数据分散存储在多张表中，能有效提升数据检索能力。这些拆分出来的数据表，即可以处于一个库中，也可以分库存储。

存储在一个数据库中

![20](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/20.png)

存储在多个库中

![21](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/21.png)

优点：

- 尽量避免了跨库 join 操作
- 解决了超大型表的性能瓶颈问题
- 事务处理相对简单
- 只要拆分的规则合适，具有极高的扩展性

缺点：

- 拆分规则不好明确，规则一定会和业务挂钩，例如根据 id、时间等
- 数据的位置不确定，难以维护
- 多数据源管理难度增大，代码的复杂度也随之增加
- 存在分布式事务问题
- 数据库维护成本增加

# 6. Mycat 核心思想

## 6.1 概述

数据拆分后会产生诸多问题，对于这些问题的解决，可以借助数据库中间件，现在比较流行的数据库中间件是使用 Mycat。

Mycat 是一款数据库中间件，对于应用程序来说是完全透明的，不管底层的数据如何拆分，应用只需要连接 Mycat 即可完成对数据的操作。

Mycat 支持MySQL、SQL Server、Oracle、DB2、PostgreSQL等主流数据库，需要注意的是，Mycat 不会存储数据，它仅仅是对数据进行路由。

Mycat 的底层是基于拦截思想实现的，当拦截到 SQL 语句时，首先会对 SQL 做一些特定的分析（分片分析、路由分析、读写分离分析、缓存分析等），然后将 SQL 发往真实的数据库，并将结果做适当的处理，最终返回给用户。

![22](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/22.png)

## 6.2 Mycat 特性

- 支持SQL92标准
- 遵守Mysql原生协议，跨语言，跨平台，跨数据库的通用中间件代理。
- 基于心跳的自动故障切换，支持读写分离，支持MySQL主从，以及galera cluster集群。
- 支持Galera for MySQL集群，Percona Cluster或者MariaDB cluster
- 基于Nio实现，有效管理线程，高并发问题。
- 支持数据的多片自动路由与聚合，支持sum,count,max等常用的聚合函数。
- 支持单库内部任意join，支持跨库2表join。
- 支持通过全局表，ER关系的分片策略，实现了高效的多表join查询。
- 支持多租户方案。
- 支持分布式事务（弱xa）。
- 支持全局序列号，解决分布式下的主键生成问题。
- 分片规则丰富，插件化开发，易于扩展。
- 强大的web，命令行监控。
- 支持前端作为mysq通用代理，后端JDBC方式支持Oracle、DB2、SQL Server 、 mongodb 。
- 支持密码加密
- 支持服务降级
- 支持IP白名单
- 支持SQL黑名单、sql注入攻击拦截
- 支持分表（1.6）
- 集群基于ZooKeeper管理，在线升级，扩容，智能优化，大数据处理（2.0开发版）。

## 6.3 下载和安装

下载地址：http://dl.mycat.org.cn/

Mycat 无需安装，解压即可运行。

核心配置文件介绍

`server.xml` ：Mycat 服务参数及用户授权配置

`schema.xml` ：逻辑库、逻辑表、数据节点、主机、分片等配置

`rule.xml` ：分片规则配置文件

## 6.4 Mycat 核心概念

在学习Mycat首先需要先对其内部一些核心概念有足够的了解。

- **逻辑库**

  > Mycat中的虚拟数据库。对应实际数据库的概念。在没有使用mycat时，应用需要确定当前连接的数据库等信息，那么当使用mycat后，也需要先虚拟一个数据库，用于应用的连接。

- **逻辑表**

  > mycat中的虚拟数据表。对应数据库中数据表的概念。

- **非分片表**

  > 没有进行数据切分的表。

- **分片表**

  > 已经被数据拆分的表，每个分片表中都有原有数据表的一部分数据。多张分片表可以构成一个完整数据表。

- **ER表**

  > 子表的记录与所关联的父表记录存放在同一个数据分片上，即子表依赖于父表，通过表分组（Table Group）保证数据Join不会跨库操作。表分组（Table Group）是解决跨分片数据join的一种很好的思路，也是数据切分规划的重要一条规则

- **全局表**

  > 可以理解为是一张数据冗余表，如状态表，每一个数据分片节点又保存了一份状态表数据。数据冗余是解决跨分片数据join的一种很好的思路，也是数据切分规划的另外一条重要规则。

- **分片节点（dataNode）**

  > 数据切分后，每一个数据分片表所在的数据库就是分片节点。

- **节点主机（dataHost）**

  > 数据切分后，每个分片节点（dataNode）不一定都会独占一台机器，同一机器上面可以有多个分片数据库，这样一个或多个分片节点（dataNode）所在的机器就是节点主机（dataHost）,为了规避单节点主机并发数限制，尽量将读写压力高的分片节点（dataNode）均衡的放在不同的节点主机（dataHost）。

- **分片规则（rule）**

  > 按照某种业务规则把数据分到某个分片的规则就是分片规则。

- **全局序列号（sequence）**

  > 也可以理解为分布式id。数据切分后，原有的关系数据库中的主键约束在分布式条件下将无法使用，因此需要引入外部机制保证数据唯一性标识，这种保证全局性的数据唯一标识的机制就是全局序列号（sequence），如UUID、雪花算法等。

# 7. Mycat 企业级应用实践

## 7.1 配置用户信息

`server.xml`

```xml
<!--配置自定义用户信息-->
<!--连接用户名-->
<user name="mycat">
    <!--连接密码-->
    <property name="password">123456</property>
    <!--创建虚拟数据库-->
    <property name="schemas">COMPANY</property>
</user>
```

## 7.2 数据非分片

配置

`schema.xml`

```xml
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
        <!--逻辑库-->
        <schema name="COMPANEY" checkSQLschema="true" sqlMaxLimit="100" dataNode="dn1">
            <!--逻辑表-->
            <table name="employees" dataNode="dn1"/>
        </schema>
        <dataNode name="dn1" dataHost="host1" database="company" />
        <dataHost name="host1" maxCon="1000" minCon="10" balance="0"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <!--心跳检测-->
                <heartbeat>select user()</heartbeat>
                <!--写主机-->
                <writeHost host="hostM1" url="172.17.0.2:3306" user="root"
                                   password="123456">
                </writeHost>
        </dataHost>  
</mycat:schema> 
```

测试通过 Mycat 操作数据库

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

![23](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/23.png)

## 7.3 数据分片

配置

`schema.xml`

```xml
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">
        <!--逻辑库-->
        <schema name="COMPANEY" checkSQLschema="true" sqlMaxLimit="100" dataNode="dn1">
            <!--
				逻辑表

				subTables：分表的名称，table1,table2,table3，如果分片较多，可以使用 $ 连接符，employees$1-3
			-->
            <table name="employees" dataNode="dn1" subTables="employees$1-3" rule="mod-long"/>
        </schema>
        <dataNode name="dn1" dataHost="host1" database="company" />
        <dataHost name="host1" maxCon="1000" minCon="10" balance="0"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <!--心跳检测-->
                <heartbeat>select user()</heartbeat>
                <!--写主机-->
                <writeHost host="hostM1" url="172.17.0.2:3306" user="root"
                                   password="123456">
                </writeHost>
        </dataHost>  
</mycat:schema> 
```

`rule.xml`

```xml
<tableRule name="mod-long">
    <rule>
        <!--用于取模的字段-->
        <columns>emp_no</columns>
        <algorithm>mod-long</algorithm>
    </rule>
</tableRule>

<function name="mod-long" class="io.mycat.route.function.PartitionByMod">
    <!-- how many data nodes -->
    <!-- 分片 / 数据节点的数量 -->
    <property name="count">3</property>
</function>
```

创建3张子表

```xml
CREATE TABLE `employees1`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4;

CREATE TABLE `employees2`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4;

CREATE TABLE `employees3`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4;
```

测试分片操作，插入20条数据，这些数据将会被存储在3张子表中。

```sql
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

通过 Mycat 查询逻辑表时，Mycat 会从所有的子表中把符合条件的数据全部查出来，合并数据后再返回。

![24](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/24.png)

## 7.4 全局序列号

当数据切分后，数据会存储多张表中，如果仍然通过数据库自增 ID 的方式，就会出现 ID 重复的情况。

要接解决这个问题需要用到全局序列号，比较常见的全局序列是使用雪花算法生成分布式 ID。

Mycat 也提供了四种方式来生成分布式ID。

### 7.4.1 本地文件方式

将全局ID存储在本地，由 Mycat 进行维护，特点是本地加载，速度快。

需要注意的是当 Mycat 重新发布后，全局序列会被恢复到初始值

配置

`sequence_conf.properties`

```properties
EMPLOYEES.HISIDS=      #使用过的历史分段，可不配置
EMPLOYEES.MINID=10000  #最小ID值
EMPLOYEES.MAXID=99999  #最大ID值
EMPLOYEES.CURID=10001  #当前ID值
```

`server.xml`

```xml
<!--设置全局序号生成方式
   0：文件
   1：数据库
   2：时间戳
   3：zookeeper
  -->
<property name="sequnceHandlerType">0</property>
```

测试本地文件全局序列

```sql
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) 
	VALUES ('next value for MYCATSEQ_EMPLOYEES', '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');

select * from EMPLOYEES;
```

![25](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/25.png)

### 7.4.2 数据库方式

基于数据的方式来生成全局序列，为了减轻数据库压力，Mycat 支持一次从数据库中获取多个 ID 缓存到本地，用完再取。

创建表以及相关函数

```sql
DROP TABLE IF EXISTS MYCAT_SEQUENCE;
CREATE TABLE MYCAT_SEQUENCE (  name VARCHAR(64) NOT NULL,  current_value BIGINT(20) NOT NULL,  increment INT NOT NULL DEFAULT 1, PRIMARY KEY (name) ) ENGINE=InnoDB;

-- ----------------------------
-- Function structure for `mycat_seq_currval`
-- ----------------------------
DROP FUNCTION IF EXISTS `mycat_seq_currval`;
DELIMITER ;;
CREATE FUNCTION `mycat_seq_currval`(seq_name VARCHAR(64)) RETURNS varchar(64) CHARSET latin1
    DETERMINISTIC
BEGIN
    DECLARE retval VARCHAR(64);
    SET retval="-1,0";
    SELECT concat(CAST(current_value AS CHAR),",",CAST(increment AS CHAR) ) INTO retval FROM MYCAT_SEQUENCE  WHERE name = seq_name;
    RETURN retval ;
END
;;
DELIMITER ;

-- ----------------------------
-- Function structure for `mycat_seq_nextval`
-- ----------------------------
DROP FUNCTION IF EXISTS `mycat_seq_nextval`;
DELIMITER ;;
CREATE FUNCTION `mycat_seq_nextval`(seq_name VARCHAR(64)) RETURNS varchar(64) CHARSET latin1
    DETERMINISTIC
BEGIN
    DECLARE retval VARCHAR(64);
    DECLARE val BIGINT;
    DECLARE inc INT;
    DECLARE seq_lock INT;
    set val = -1;
    set inc = 0;
    SET seq_lock = -1;
    SELECT GET_LOCK(seq_name, 15) into seq_lock;
    if seq_lock = 1 then
      SELECT current_value + increment, increment INTO val, inc FROM MYCAT_SEQUENCE WHERE name = seq_name for update;
      if val != -1 then
          UPDATE MYCAT_SEQUENCE SET current_value = val WHERE name = seq_name;
      end if;
      SELECT RELEASE_LOCK(seq_name) into seq_lock;
    end if;
    SELECT concat(CAST((val - inc + 1) as CHAR),",",CAST(inc as CHAR)) INTO retval;
    RETURN retval;
END
;;
DELIMITER ;

-- ----------------------------
-- Function structure for `mycat_seq_setvals`
-- ----------------------------
DROP FUNCTION IF EXISTS `mycat_seq_nextvals`;
DELIMITER ;;
CREATE FUNCTION `mycat_seq_nextvals`(seq_name VARCHAR(64), count INT) RETURNS VARCHAR(64) CHARSET latin1
    DETERMINISTIC
BEGIN
    DECLARE retval VARCHAR(64);
    DECLARE val BIGINT;
    DECLARE seq_lock INT;
    SET val = -1;
    SET seq_lock = -1;
    SELECT GET_LOCK(seq_name, 15) into seq_lock;
    if seq_lock = 1 then
        SELECT current_value + count INTO val FROM MYCAT_SEQUENCE WHERE name = seq_name for update;
        IF val != -1 THEN
            UPDATE MYCAT_SEQUENCE SET current_value = val WHERE name = seq_name;
        END IF;
        SELECT RELEASE_LOCK(seq_name) into seq_lock;
    end if;
    SELECT CONCAT(CAST((val - count + 1) as CHAR), ",", CAST(val as CHAR)) INTO retval;
    RETURN retval;
END
;;
DELIMITER ;

-- ----------------------------
-- Function structure for `mycat_seq_setval`
-- ----------------------------
DROP FUNCTION IF EXISTS `mycat_seq_setval`;
DELIMITER ;;
CREATE FUNCTION `mycat_seq_setval`(seq_name VARCHAR(64), value BIGINT) RETURNS varchar(64) CHARSET latin1
    DETERMINISTIC
BEGIN
    DECLARE retval VARCHAR(64);
    DECLARE inc INT;
    SET inc = 0;
    SELECT increment INTO inc FROM MYCAT_SEQUENCE WHERE name = seq_name;
    UPDATE MYCAT_SEQUENCE SET current_value = value WHERE name = seq_name;
    SELECT concat(CAST(value as CHAR),",",CAST(inc as CHAR)) INTO retval;
    RETURN retval;
END
;;
DELIMITER ;

INSERT INTO MYCAT_SEQUENCE VALUES ('GLOBAL', 1, 1);
```

> 添加 EMPLOYEES 全局序列

字段说明

![26](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/26.png)

配置

`server.xml`

```xml
<!--设置全局序号生成方式
   0：文件
   1：数据库
   2：时间戳
   3：zookeeper
  -->
<property name="sequnceHandlerType">1</property>
```

`sequence_db_conf.properties`

```properties
#sequence stored in datanode
GLOBAL=dn1
COMPANY=dn1
CUSTOMER=dn1
ORDERS=dn1

#添加 EMPLOYEES
EMPLOYEES=dn1
```

测试基于数据库的方式生成全局序列

```sql
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) 
	VALUES ('next value for MYCATSEQ_EMPLOYEES', '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');

select * from EMPLOYEES;
```

![27](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/27.png)

### 7.4.3 本地时间戳方式

ID= 64 位二进制 (42(毫秒)+5(机器 ID)+5(业务编码)+12(重复累加) ，换算成十进制为 18 位数的 long 类型，每毫秒可以并发 12 位二进制的累加（65535）。

配置

`server.xml`

```xml
<!--设置全局序号生成方式
   0：文件
   1：数据库
   2：时间戳
   3：zookeeper
  -->
<property name="sequnceHandlerType">2</property>
```

`sequence_time_conf.properties`

```properties
#sequence depend on TIME
WORKID=01
DATAACENTERID=01
```

测试本地时间戳方式生成全局序列

```sql
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) 
	VALUES ('next value for MYCATSEQ_EMPLOYEES', '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');

select * from EMPLOYEES;
```

> 注意：
>
> - MYCATSEQ_  后面的内容可以随意指定，不限制
>
> - emp_no 字段类型要改成 bigint

![28](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/28.png)

### 7.4.4 分布式 ZK ID 生成器

ID 结构

> current time millis(微秒时间戳 38 位,可以使用 17 年)
>
> +
>
> clusterId（机房或者 ZKid，通过配置文件配置 5 位）
>
> +
>
> instanceId（实例 ID，可以通过 ZK 或者配置文件获取，5 位）
>
> +
>
> threadId（线程 ID，9 位） 
>
> +
>
> increment(自增，6 位)

特点：

- 一共 63 位，可承受单机房单及其单线程 1000*(2^6) = 640000 的并发。

- 无悲观锁，无强竞争，吞吐量更高

安装 zk

```shell
docker run -d --name zk -p 2181:2181 zookeeper
```

配置

`server.xml`

```xml
<!--设置全局序号生成方式
   0：文件
   1：数据库
   2：时间戳
   3：zookeeper
  -->
<property name="sequnceHandlerType">3</property>
```

`sequence_distributed_conf.properties`

```properties
INSTANCEID=ZK #声明使用zk生成
CLUSTERID=01
```

`myid.properties`

```properties
loadZk=true
zkURL=172.17.0.3:2181
clusterId=01
myid=mycat_fz_01
clusterNodes=mycat_fz_01
```

测试 zk 生成全局序列

```sql
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) 
	VALUES ('next value for MYCATSEQ_EMPLOYEES', '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');

select * from EMPLOYEES;
```

> 注意：
>
> - MYCATSEQ_  后面的内容可以随意指定，不限制
>
> - emp_no 字段类型要改成 bigint

![29](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/29.png)

## 7.5 垂直拆分 & 读写分离

当所有的表都存放在一台数据库，造成性能瓶颈时，可以使用垂直拆分，根据业务情况对表进行分类，将表存储到不同的数据库中，配合主从复制，还可以做读写分离，进一步提高数据库的吞吐量。

架构设计

![30](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/30.png)

案例演示：将员工表和部门表拆分到不同的数据库。

## 7.6 搭建主从复制环境

搭建 MySQL 主从复制

创建两对单主单从的主从复制架构，参考 - 单主单从

搭建 Mycat

配置用户

`server.xml`

```xml
<!--配置自定义用户信息-->
<!--连接用户名-->
<user name="mycat">
    <!--连接密码-->
    <property name="password">123456</property>
    <!--创建虚拟数据库-->
    <property name="schemas">COMPANY</property>
</user>
```

配置垂直拆分和读写分离

`schema.xml`

```xml
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">

        <schema name="TESTDB" checkSQLschema="true" sqlMaxLimit="100" randomDataNode="dn1">
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">

        <schema name="COMPANY" checkSQLschema="true" sqlMaxLimit="100">
                <table name="employees" dataNode="dn1"/>
                <table name="departments" dataNode="dn2"/>
        </schema>
        <dataNode name="dn1" dataHost="host1" database="company" />
        <dataNode name="dn2" dataHost="host2" database="company" />

        <dataHost name="host1" maxCon="1000" minCon="10" balance="1"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <heartbeat>select user()</heartbeat>
                <writeHost host="hostM1" url="192.168.100.129:3306" user="root" password="123456">
                        <readHost host="hostS1" url="192.168.100.129:3307" user="root" password="123456"/>
                </writeHost>
        </dataHost>

        
        <dataHost name="host2" maxCon="1000" minCon="10" balance="1"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <heartbeat>select user()</heartbeat>
                <writeHost host="hostM1" url="192.168.100.130:3306" user="root" password="123456">
                        <readHost host="hostS1" url="192.168.100.130:3307" user="root" password="123456"/>
                </writeHost>
        </dataHost>
</mycat:schema>
```

测试

员工表

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

部门表

```sql
CREATE TABLE `departments`  (
  `dept_no` char(4),
  `dept_name` varchar(40),
  PRIMARY KEY (`dept_no`),
  UNIQUE INDEX `dept_name`(`dept_name`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4;


INSERT INTO `DEPARTMENTS` VALUES ('d001', 'Marketing');
INSERT INTO `DEPARTMENTS` VALUES ('d002', 'Finance');
INSERT INTO `DEPARTMENTS` VALUES ('d003', 'Human Resources');
INSERT INTO `DEPARTMENTS` VALUES ('d004', 'Production');
INSERT INTO `DEPARTMENTS` VALUES ('d005', 'Development');
INSERT INTO `DEPARTMENTS` VALUES ('d006', 'Quality Management');
INSERT INTO `DEPARTMENTS` VALUES ('d007', 'Sales');
INSERT INTO `DEPARTMENTS` VALUES ('d008', 'Research');
INSERT INTO `DEPARTMENTS` VALUES ('d009', 'Customer Service');
```

可以观察到员工表和部门表分别落在了不同的数据库上

![31](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/31.png)

## 7.7 水平拆分

假设，现在员工表中的数据以及非常多了，数据检索非常的慢，我们可以对员工表进行水平拆分，在前面的数据分片章节中，我们简单介绍了水平拆分，拆分后的子表仍然处于同一个数据库中。现在，我们尝试将表拆分后放到不同的数据库。

配置

`schema.xml`

```xml
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">

        <schema name="COMPANY" checkSQLschema="true" sqlMaxLimit="100">
                <!--将员工表拆分到dn1和dn2两个节点上，拆分的规则是按照员工编号取模-->
                <table name="employees" dataNode="dn1,dn2" rule="mod-emp-no"/>
                <table name="departments" dataNode="dn2"/>
        </schema>
        <dataNode name="dn1" dataHost="host1" database="company" />
        <dataNode name="dn2" dataHost="host2" database="company" />

        <dataHost name="host1" maxCon="1000" minCon="10" balance="1"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <heartbeat>select user()</heartbeat>
                <writeHost host="hostM1" url="192.168.100.129:3306" user="root" password="123456">
                        <readHost host="hostS1" url="192.168.100.129:3307" user="root" password="123456"/>
                </writeHost>
        </dataHost>

        
        <dataHost name="host2" maxCon="1000" minCon="10" balance="1"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <heartbeat>select user()</heartbeat>
                <writeHost host="hostM1" url="192.168.100.130:3306" user="root" password="123456">
                        <readHost host="hostS1" url="192.168.100.130:3307" user="root" password="123456"/>
                </writeHost>
        </dataHost>
</mycat:schema>
```

`rule.xml`

```xml
<!--添加一个拆分规则-->
<tableRule name="mod-emp-no">
    <rule>
        <columns>emp_no</columns>
        <algorithm>mod-long</algorithm>
    </rule>
</tableRule>



<function name="mod-long" class="io.mycat.route.function.PartitionByMod">
    <!-- 由于只有两个数据几点，取模的参数要改成2 -->
    <property name="count">2</property>
</function>
```

测试

可以观察到，员工表被拆分到了两个数据库中，并且数据也是分散在不同的数据库。

![32](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/32.png)

## 7.8 Mycat 分片规则

前面我们尝试将数据库进行分片操作，分片操作的关键是制定分片的规则，合适的分片规则更有利于后期的架构扩展。

Mycat 给我们提供了一系列的分片规则，包括：

- 枚举分片
- 固定 hash 分片
- 固定范围分片
- 取模
- 取模范围分片
- 字符串 hash 取模范围分片
- 一致性 hash 分片
- 时间分片（按天分片、按月分片）

### 7.8.1 枚举分片

适用于在特定业务场景下，将不同的数据存放于不同的数据库中，如按省份存放订单、按存放人员信息等。

配置

`schema.xml`

```xml
<schema name="COMPANY" checkSQLschema="true" sqlMaxLimit="100">
    <!--将员工表拆分到dn1和dn2两个节点上-->
    <table name="employees" dataNode="dn1,dn2" rule="sharding-by-intfile"/>
    <table name="departments" dataNode="dn2"/>
</schema>
```

`rule.xml`

```xml
<tableRule name="sharding-by-intfile">
    <rule>
        <columns>gender</columns>
        <algorithm>hash-int</algorithm>
    </rule>
</tableRule>


<function name="hash-int"
          class="io.mycat.route.function.PartitionByFileMap">
    <!--枚举配置文件-->
    <property name="mapFile">partition-hash-int.txt</property>
    <!--字段类型，0表示Integer，非0表示String-->
    <property name="type">1</property>
</function>

```

`partition-hash-int.txt`

```
M=0
F=1
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

插入的数据根据性别存储到不同的分片中。

![33](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/33.png)

![34](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/34.png)

问题：该方案适用于特定业务场景进行数据分片，但该方式容易出现数据倾斜。

### 7.8.2 固定 hash 分片

本条规则类似于十进制的求模运行，区别是固定 hash 分片采用的是二进制操作，实现方式是：字段值的二进制低10位 & 1111111111。

固定 hash 分片的分区总长度为1024，可根据需要将其拆分成不同长度的分区，Mycat 会根据二进制运行结果来确定数据要存储到哪一个分区。

举例：

|---- 256 ---- |---- 256 ---- |-------------- 512 --------------|

这个策略是将数据分为3分，前两份各占25%，第三份占50%。

> 1024的二进制&1111111111运算后为0，落入第 1 个分区
>
> 266的二进制&1111111111运算后为266，落入第 2 个分区
>
> 1023的二进制&1111111111运算后为1023，落入第 3 个分区

配置

`schema.xml`

```xml
<schema name="COMPANY" checkSQLschema="true" sqlMaxLimit="100">
    <!--将员工表拆分到dn1和dn2两个节点上-->
    <table name="employees" dataNode="dn1,dn2" rule="partition-by-fixed-hash"/>
    <table name="departments" dataNode="dn2"/>
</schema>
```

`rule.xml`

```xml
<!--添加一个规则-->    
<tableRule name="partition-by-fixed-hash">
    <rule>
        <columns>emp_no</columns>
        <algorithm>partition-by-fixed-hash</algorithm>
    </rule>
</tableRule>

<!-- 1*256+1*768=1024 -->
<function name="partition-by-fixed-hash" class="io.mycat.route.function.PartitionByLong">
    <!--节点数量-->
    <property name="partitionCount">1,1</property>
    <!--分区范围-->
    <property name="partitionLength">256,768</property>
</function>
```

更多的分区配置示例

```xml
<!-- 4*256=1024 -->
<function name="partition-by-fixed-hash" class="io.mycat.route.function.PartitionByLong">
    <!--节点数量-->
    <property name="partitionCount">4</property>
    <!--分区范围-->
    <property name="partitionLength">256</property>
</function>

<!-- 1*256+2*256+1*256=1024 -->
<function name="partition-by-fixed-hash" class="io.mycat.route.function.PartitionByLong">
    <!--节点数量-->
    <property name="partitionCount">1,2,1</property>
    <!--分区范围-->
    <property name="partitionLength">256,256,256</property>
</function>

<!-- 1*256+1*512+1*256=1024 -->
<function name="partition-by-fixed-hash" class="io.mycat.route.function.PartitionByLong">
    <!--节点数量-->
    <property name="partitionCount">1,1,1</property>
    <!--分区范围-->
    <property name="partitionLength">256,512,256</property>
</function>
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10101, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10202, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10303, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10404, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10505, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10606, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10707, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10808, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10909, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
```

![35](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/35.png)

![36](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/36.png)

### 7.8.3 固定范围分片

此分片适用于，提前规划好分片字段某个范围属于哪个分片。

优点：能够知道某个分片字段的某个范围具体在哪一个节点

缺点：如果短时间内有大量的批量插入操作，那么某个分片节点可能一下子会承受比较大的数据库压力，而别的分片节点此时可能处于闲置状态，无法利用其它节点进行分担压力。

配置

`schema.xml`

```xml
<table name="employees" dataNode="dn1,dn2" rule="auto-sharding-long"/>
```

`rule.xml`

```xml
<tableRule name="auto-sharding-long">
    <rule>
        <columns>emp_no</columns>
        <algorithm>rang-long</algorithm>
    </rule>
</tableRule>
```

`autopartition-long.txt`

```
#所有的节点配置都是从0开始，0代表节点1
10001-10010=0
10011-10020=1
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

![37](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/37.png)

![38](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/38.png)

### 7.8.4 取模

此规则为对分片字段求摸运算

相关操作参考 - 水平拆分

### 7.8.5 取模范围分片

这种方式结合了范围分片和取模分片，主要是为后续的数据迁移做准备，可以自主决定取模后数据的节点 分布。

配置

`schema.xml`

```xml
<table name="employees" dataNode="dn1,dn2" rule="sharding-by-partition"/>
```

`rule.xml`

```xml
<!--添加分片规则-->
<tableRule name="sharding-by-partition">
    <rule>
        <columns>emp_no</columns>
        <algorithm>sharding-by-partition</algorithm>
    </rule>
</tableRule>

<!--添加分片函数-->
<function name="sharding-by-partition" class="io.mycat.route.function.PartitionByPattern">
    <!--求模基数-->
    <property name="patternValue">256</property>
    <!--指定规则配置文件-->
    <property name="mapFile">partition-pattern.txt</property>
    <!--默认节点-->
    <property name="defaultNode">0</property>
</function>
```

`partition-pattern.txt` `新创建`

```
#0-128表示id%256后的数据范围。
0-128=0
129-256=1
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10202, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10204, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10206, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10208, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10210, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10212, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10214, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10216, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10218, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10220, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

![39](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/39.png)

![40](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/40.png)

### 7.8.6 字符串 hash 取模范围分片

在某些业务场景下，有时可能会根据某个分片字段的前几个值来进行取模。如地址信息只取省份、姓名只取前一个字的姓等。此时则可以使用该种方式。

获取前 `prefixLength` 位所有 ASCII 码的和进行求模，得到结果后，再根据配置来确定存储节点位置。

配置

`schema.xml`

```xml
<table name="employees" dataNode="dn1,dn2" rule="sharding-by-string-hash"/>
```

`rule.xml`

```xml
<!--添加分片规则-->
<tableRule name="sharding-by-string-hash">
    <rule>
        <columns>first_name</columns>
        <algorithm>sharding-by-string-hash-function</algorithm>
    </rule>
</tableRule>

<!--添加分片函数-->
<function name="sharding-by-string-hash-function" class="io.mycat.route.function.PartitionByPrefixPattern">
    <!--求模基数 -->
    <property name="patternValue">26</property>
    <!-- 截取的位数  -->
    <property name="prefixLength">1</property>
    <!--指定规则配置文件-->
    <property name="mapFile">partition-pattern-string-hash.txt</property>
</function>
```

`partition-pattern-string-hash.txt` `新创建`

```xml
0-12=0
13-25=1
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

![41](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/41.png)

![42](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/42.png)

### 7.8.7 一致性 hash 分片

通过一致性hash分片可以最大限度的让数据均匀分布。

原理

一致性hash算法引入了hash环的概念。环的大小是0~2^32-1。首先通过crc16算法计算出数据节点在hash环中的位置。

![43](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/43.png)

当存储数据时，也会采用相同的算法，计算出数据 key 的 hash 值，映射到 hash 环上。

![44](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/44.png)

然后从数据映射的位置开始，顺时针找到距离最近的数据节点，并将该数据存入该节点中。

![45](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/45.png)

此时可以发现，数据并没有达到预期的数据均匀，可以发现如果两个数据节点在环上的距离，决定有大量数据存入了dataNode2，而仅有少量数据存入dataNode1。

为了解决数据不均匀的问题，在mycat中可以设置 **虚拟数据映射节点**。同时这些虚拟节点会映射到实际数据节点。

![46](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/46.png)

数据仍然以顺时针方式寻找数据节点，当找到最近的数据节点无论是实际还是虚拟，都会进行存储，如果是虚拟数据节点的话，最终会将数据保存到实际数据节点中。 从而尽量的使数据均匀分布。

配置

`schema.xml`

```xml
<table name="employees" dataNode="dn1,dn2" rule="sharding-by-murmur"/>
```

`rule.xml`

```xml
<!--修改规则中的字段名-->
<tableRule name="sharding-by-murmur">
    <rule>
        <columns>emp_no</columns>
        <algorithm>murmur</algorithm>
    </rule>
</tableRule>

<!--函数-->
<function name="murmur"
          class="io.mycat.route.function.PartitionByMurmurHash">
    <property name="seed">0</property><!-- 默认是0 -->
    <property name="count">2</property><!-- 要分片的数据库节点数量，必须指定，否则没法分片 -->
    <property name="virtualBucketTimes">160</property><!-- 一个实际的数据库节点被映射为这么多虚拟节点，默认是160倍，也就是虚拟节点数是物理节点数的160倍 -->
</function>
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

![47](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/47.png)

![48](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/48.png)

### 7.8.8 时间分片（按天分片）

当数据量非常大时，有时会考虑，按天去分库分表。这种场景是非常常见的。同时也有利于后期的数据查询。

配置

`schema.xml`

```xml
<table name="employees" dataNode="dn1,dn2" rule="sharding-by-date"/>
```

`rule.xml`

```xml
<!--修改分片字段-->
<tableRule name="sharding-by-date">
    <rule>
        <columns>birth_date</columns>
        <algorithm>partbyday</algorithm>
    </rule>
</tableRule>

<function name="partbyday"
          class="io.mycat.route.function.PartitionByDate">
    <!--日期格式-->
    <property name="dateFormat">yyyy-MM-dd</property>
    <property name="sNaturalDay">0</property>
    <!--从什么时间开始-->
    <property name="sBeginDate">1980-01-01</property>
    <!--每隔几天一个分片-->
    <property name="sPartionDay">10</property>
</function>
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4

INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1980-01-01', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1980-01-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1980-01-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1980-01-04', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1980-01-05', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1980-01-06', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1980-01-07', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1980-01-08', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1980-01-09', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1980-01-10', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1980-01-11', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1980-01-12', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1980-01-13', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1980-01-14', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1980-01-15', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1980-01-16', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1980-01-17', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1980-01-18', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1980-01-19', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1980-01-20', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

![49](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/49.png)

![50](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/50.png)

### 7.8.9 时间分片（按月分片）

按月进行数据分片，每月一个分片。

配置

`schema.xml`

```xml
<table name="employees" dataNode="dn1,dn2" rule="sharding-by-month"/>
```

`rule.xml`

```xml
<!--修改分片字段-->
<tableRule name="sharding-by-month">
    <rule>
        <columns>birth_date</columns>
        <algorithm>partbymonth</algorithm>
    </rule>
</tableRule>

<function name="partbymonth"
          class="io.mycat.route.function.PartitionByMonth">
    <property name="dateFormat">yyyy-MM-dd</property>
    <!--从什么时间开始-->
    <property name="sBeginDate">1980-01-01</property>
</function>
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4


INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1980-01-01', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1980-01-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1980-01-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1980-01-04', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1980-01-05', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1980-01-06', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1980-01-07', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1980-01-08', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1980-01-09', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1980-01-10', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1980-02-01', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1980-02-02', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1980-02-03', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1980-02-04', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1980-02-05', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1980-02-06', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1980-02-07', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1980-02-08', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1980-02-09', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1980-02-10', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

![51](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/51.png)

![52](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/52.png)

## 7.9 跨库 join

### 7.9.1 全局表

系统中基本都会存在数据字典信息，如数据分类信息、项目的配置信息等。这些字典数据最大的特点就是数据量不大并且很少会被改变。同时绝大多数的业务场景都会涉及到字典表的操作。 因此为了避免频繁的跨库join操作，结合冗余数据思想，可以考虑把这些字典信息在每一个分库中都存在一份。

mycat在进行join操作时，当业务表与全局表进行聚合会<font color='red'>优先选择相同分片的全局表，从而避免跨库join操作。在进行数据插入时，会把数据同时插入到所有分片的全局表中</font>。

配置

`shcema.xml`

```xml
<table name="departments" dataNode="dn1,dn2" type="global"/>
```

### 7.9.2 ER 表

ER表也是一种为了避免跨库join的手段，在业务开发时，经常会使用到主从表关系的查询，如商品表与商品详情表。

不使用 ER 表的问题演示

配置

`schema.xml`

```xml
<schema name="COMPANY" checkSQLschema="true" sqlMaxLimit="100">
    <!--将员工表拆分到dn1和dn2两个节点上-->
    <table name="employees" dataNode="dn1,dn2" rule="mod-emp-no"/>
    <!--中间表-->
    <table name="dept_emp" dataNode="dn1"/>
    <table name="departments" dataNode="dn1,dn2" type="global"/>
</schema>
```

测试

```sql
CREATE TABLE `EMPLOYEES`  (
  `emp_no` int(0) NOT NULL,
  `birth_date` date NOT NULL,
  `first_name` varchar(14) NOT NULL,
  `last_name` varchar(16) NOT NULL,
  `gender` enum('M','F') NOT NULL,
  `hire_date` date NOT NULL,
  PRIMARY KEY (`emp_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4;


INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10001, '1953-09-02', 'Georgi', 'Facello', 'M', '1986-06-26');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10002, '1964-06-02', 'Bezalel', 'Simmel', 'F', '1985-11-21');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10003, '1959-12-03', 'Parto', 'Bamford', 'M', '1986-08-28');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10004, '1954-05-01', 'Chirstian', 'Koblick', 'M', '1986-12-01');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10005, '1955-01-21', 'Kyoichi', 'Maliniak', 'M', '1989-09-12');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10006, '1953-04-20', 'Anneke', 'Preusig', 'F', '1989-06-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10007, '1957-05-23', 'Tzvetan', 'Zielinski', 'F', '1989-02-10');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10008, '1958-02-19', 'Saniya', 'Kalloufi', 'M', '1994-09-15');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10009, '1952-04-19', 'Sumant', 'Peac', 'F', '1985-02-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10010, '1963-06-01', 'Duangkaew', 'Piveteau', 'F', '1989-08-24');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10011, '1953-11-07', 'Mary', 'Sluis', 'F', '1990-01-22');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10012, '1960-10-04', 'Patricio', 'Bridgland', 'M', '1992-12-18');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10013, '1963-06-07', 'Eberhardt', 'Terkki', 'M', '1985-10-20');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10014, '1956-02-12', 'Berni', 'Genin', 'M', '1987-03-11');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10015, '1959-08-19', 'Guoxiang', 'Nooteboom', 'M', '1987-07-02');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10016, '1961-05-02', 'Kazuhito', 'Cappelletti', 'M', '1995-01-27');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10017, '1958-07-06', 'Cristinel', 'Bouloucos', 'F', '1993-08-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10018, '1954-06-19', 'Kazuhide', 'Peha', 'F', '1987-04-03');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10019, '1953-01-23', 'Lillian', 'Haddadi', 'M', '1999-04-30');
INSERT INTO `EMPLOYEES`(emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES (10020, '1952-12-24', 'Mayuko', 'Warwick', 'M', '1991-01-26');
```

```sql
CREATE TABLE `DEPARTMENTS`  (
  `dept_no` char(4),
  `dept_name` varchar(40),
  PRIMARY KEY (`dept_no`),
  UNIQUE INDEX `dept_name`(`dept_name`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4;

INSERT INTO `DEPARTMENTS` VALUES ('d001', 'Marketing');
INSERT INTO `DEPARTMENTS` VALUES ('d002', 'Finance');
INSERT INTO `DEPARTMENTS` VALUES ('d003', 'Human Resources');
INSERT INTO `DEPARTMENTS` VALUES ('d004', 'Production');
INSERT INTO `DEPARTMENTS` VALUES ('d005', 'Development');
INSERT INTO `DEPARTMENTS` VALUES ('d006', 'Quality Management');
INSERT INTO `DEPARTMENTS` VALUES ('d007', 'Sales');
INSERT INTO `DEPARTMENTS` VALUES ('d008', 'Research');
INSERT INTO `DEPARTMENTS` VALUES ('d009', 'Customer Service');
```

```sql
CREATE TABLE `DEPT_EMP`  (
  `emp_no` int(0) NOT NULL,
  `dept_no` char(4) NOT NULL,
  `from_date` date NOT NULL,
  `to_date` date NOT NULL,
  PRIMARY KEY (`emp_no`, `dept_no`),
  INDEX `emp_no`(`emp_no`),
  INDEX `dept_no`(`dept_no`)
) ENGINE = InnoDB CHARACTER SET = utf8mb4;


INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10001, 'd005', '1986-06-26', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10002, 'd007', '1996-08-03', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10003, 'd004', '1995-12-03', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10004, 'd004', '1986-12-01', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10005, 'd003', '1989-09-12', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10006, 'd005', '1990-08-05', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10007, 'd008', '1989-02-10', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10008, 'd005', '1998-03-11', '2000-07-31');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10009, 'd006', '1985-02-18', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10010, 'd004', '1996-11-24', '2000-06-26');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10010, 'd006', '2000-06-26', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10011, 'd009', '1990-01-22', '1996-11-09');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10012, 'd005', '1992-12-18', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10013, 'd003', '1985-10-20', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10014, 'd005', '1993-12-29', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10015, 'd008', '1992-09-19', '1993-08-22');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10016, 'd007', '1998-02-11', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10017, 'd001', '1993-08-03', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10018, 'd004', '1992-07-29', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10018, 'd005', '1987-04-03', '1992-07-29');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10019, 'd008', '1999-04-30', '9999-01-01');
INSERT INTO `DEPT_EMP`(emp_no, dept_no, from_date, to_date) VALUES (10020, 'd004', '1997-12-30', '9999-01-01');
```

查询

```sql
SELECT * FROM EMPLOYEES E JOIN DEPT_EMP DE ON E.EMP_NO = DE.EMP_NO JOIN DEPARTMENTS D ON DE.DEPT_NO = D.DEPT_NO ORDER BY E.EMP_NO
```

![53](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/53.png)

问题：无法查出第二个节点的数据

配置 ER 表

`schema.xml`

```xml
<schema name="COMPANY" checkSQLschema="true" sqlMaxLimit="100">
    <!--将员工表拆分到dn1和dn2两个节点上-->
    <table name="employees" dataNode="dn1,dn2" rule="mod-emp-no">
        <!--
                                name: 子表名称
                                parentKey: 主键
                                joinKey: 插入子表的时候会使用这个列的值查找父表存储的数据节点
                                parentKey: 属性指定的值一般为与父表建立关联关系的列名
                        -->
        <childTable name="dept_emp" primaryKey="emp_no" joinKey="emp_no" parentKey="emp_no"/>
    </table>
    <!--中间表-->
    <table name="departments" dataNode="dn1,dn2" type="global"/>
</schema>
```

测试

再次插入数据并查询

![54](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/54.png)

# 8. Mycat 企业级架构设计与应用

## 8.1 主从切换

基于Mycat主从复制方案，当前存在一个主节点和一个从节点，主节点负责写操作，从节点负责读操作。

当在一个dataHost中配置了两个或多个writeHost，如果第一个writeHost宕机，则Mycat会在默认3次心跳检查失败后，自动切换到下一个可用的writeHost执行DML语句。

![55](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/55.png)

在Mycat主从切换中，可以将从节点也配置为是一个写节点（相当于从节点同时负责读写）。当原有的master写节点宕机后，从节点会被提升为主节点，同时负责读写操作。当写节点恢复后，会被作为从节点使用，保持现有状态不变，跟随新的主节点。

​	简单点说就是：原来的主变成从，原来的从一直为主。

`schema.xml`

```xml
<schema name="COMPANY" checkSQLschema="true" sqlMaxLimit="100">
    <!--将员工表拆分到dn1和dn2两个节点上-->
    <table name="employees" dataNode="dn1"/>
</schema>
<dataNode name="dn1" dataHost="host1" database="company" />
<dataHost name="host1" maxCon="1000" minCon="10" balance="1"
          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
    <heartbeat>select user()</heartbeat>
    <writeHost host="hostM1" url="192.168.100.129:3306" user="root" password="123456">
        <readHost host="hostS1" url="192.168.100.129:3307" user="root" password="123456"/>
    </writeHost>

    <writeHost host="hostM2" url="192.168.100.129:3307" user="root" password="123456"/>
</dataHost>
```

插入数据，此时成功插入，并且会被复制到从节点

停止 master 服务，插入数据，此时将由 hostM2 负责写数据

重启 master 服务，再次插入数据，此时可以发现数据仍然会进入到 hostM2 中，因为就算之前的 hostM1 恢复了，根据mycat的规则其也不会自动提升为写节点，因此写节点仍然为 hostM2 。 

当前为主从架构，并没有配置为双向复制。所以数据进入到host2后，host1中仍然没有数据，符合预期。此时host2会同时负责读、写请求。

要解决这个问题，配置成主主双向复制即可。

## 8.2 动态扩容 & 数据迁移

在生产环境下，当原有的数据库节点已经满足不了当前的数据存储量，此时就会在现有数据库基础上新增数据节点。但是当新增数据节点后，就要考虑原有的数据应该如何迁移一部分数据到新增的数据节点上。

![56](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/56.png)

在 conf 目录下新建 `newSchema.xml` 和 `newRule.xml` 两个配置文件。

`newSchema.xml`

```xml
<?xml version="1.0"?>
<!DOCTYPE mycat:schema SYSTEM "schema.dtd">
<mycat:schema xmlns:mycat="http://io.mycat/">

        <schema name="COMPANY" checkSQLschema="true" sqlMaxLimit="100">
                <!--将员工表拆分到dn1和dn2两个节点上-->
                <table name="employees" dataNode="dn1,dn2,dn3" rule="mod-emp-no"/>
        </schema>
        <dataNode name="dn1" dataHost="host1" database="company" />
        <dataNode name="dn2" dataHost="host2" database="company" />
        <dataNode name="dn3" dataHost="host3" database="company" />

        <dataHost name="host1" maxCon="1000" minCon="10" balance="1"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <heartbeat>select user()</heartbeat>
                <writeHost host="hostM1" url="192.168.100.129:3306" user="root" password="123456">
                        <readHost host="hostS1" url="192.168.100.129:3307" user="root" password="123456"/>
                </writeHost>
        </dataHost>


        <dataHost name="host2" maxCon="1000" minCon="10" balance="1"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <heartbeat>select user()</heartbeat>
                <writeHost host="hostM1" url="192.168.100.130:3306" user="root" password="123456">
                        <readHost host="hostS1" url="192.168.100.130:3307" user="root" password="123456"/>
                </writeHost>
        </dataHost>

        <dataHost name="host3" maxCon="1000" minCon="10" balance="1"
                          writeType="0" dbType="mysql" dbDriver="native" switchType="1"  slaveThreshold="100">
                <heartbeat>select user()</heartbeat>
                <writeHost host="hostM1" url="192.168.100.133:3306" user="root" password="123456">
                        <readHost host="hostS1" url="192.168.100.133:3307" user="root" password="123456"/>
                </writeHost>
        </dataHost>
</mycat:schema>
                    
```

`newRule.xml`

newRule.xml 文件的内容从 rule.xml 拷贝。

由于数据节点的数量从2变成了3，所以取模的基数也要改成3。如果使用的是其他分片规则，根据具体情况进行修改。

```xml
<function name="mod-long" class="io.mycat.route.function.PartitionByMod">
    <property name="count">3</property>
</function>

```

修改 `conf/migrateTables.properties`

```properties
# 逻辑库=逻辑表
# TESTDB=TB1,TB2,TB3...
COMPANY=EMPLOYEES
```

`vim` 进入并修改 `dataMigrate.sh` 文件的格式

```
# 查看格式
:set ff

# 修改格式
:set ff=unix
```

修改 mysqldump 文件路径（需要安装 mysql 客户端才有这个文件）

```
#查看mysqldump文件路径
find / -name mysqldump

#修改dataMigrate.sh文件配置
RUN_CMD="$RUN_CMD -mysqlBin=/usr/bin/"
```

执行数据扩容与迁移

```
./dataMigrate.sh
```

![57](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/57.png)

![58](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/58.png)

![59](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/59.png)

![60](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/60.png)

> 注意：执行数据扩容&迁移时，务必注意虚拟库的名称必须要全部是小写或全部大写，不能大小写混合

扩容缩容成功后，将 newSchema.xml 和newRule.xml 重命名为 schema.xml 和rule.xml 并替换掉原文件，重启 mycat 服务，整个扩容缩容过程完成。

## 8.3 Haproxy + Keepalived + Mycat 高可用负载均衡

当线上服务器压力过大时，可以考虑基于keepalived进行高可用避免出现mycat单点问题，同时为了防止线上压力集中在某一台实例上，可以通过haproxy进行请求的负载均衡。

![61](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/61.png)

准备工作

- 两台 Mycat 保证高可用，并做读写分离和分库分表

- 两套主从复制的数据库

Haproxy 下载

地址：https://www.haproxy.org/#down

安装依赖包

```
yum install -y gcc-c++
```

编译安装

```
make TARGET=linux2628

make install PREFIX=/usr/local/haproxy
```

创建配置文件

`/usr/local/haproxy/haproxy.cfg`

```
global
    log         127.0.0.1 local2
    maxconn     4000
    daemon

defaults
        log			global
        log			127.0.0.1 local3
        mode			http
        option			tcplog
        option			dontlognull
        retries			10
        option redispatch
        maxconn			2000
        timeout connect		10s
        timeout client          1m
        timeout server          1m
        timeout http-keep-alive 10s
        timeout check           10s

listen admin_stats
        bind 		0.0.0.0:10080
        mode 		http
        option 		httplog
        maxconn 	10
        stats 		refresh 30s
        stats 		uri /admin
        stats 		realm XingCloud\ Haproxy
        stats 		auth admin:admin #用这个账号登录，可以自己设置
        stats 		hide-version
        stats 		admin if TRUE
        
listen  mycat_server_list
        bind 	0.0.0.0:3300
        mode 	tcp
        balance roundrobin #轮询
        server 	mycat131 192.168.100.131:8066 check port 8066 maxconn 300
        server 	mycat232 192.168.100.132:8066 check port 8066 maxconn 300
```

启动 haproxy

```shell
# 进入目录
[root@localhost ~]# cd /usr/local/haproxy/

# 启动
[root@localhost haproxy]# ./sbin/haproxy -f haproxy.cfg
```

访问管理页面

```
http://192.168.100.131:10080/admin
http://192.168.100.132:10080/admin
```

![62](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/62.png)

![63](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/63.png)

![64](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/64.png)

Keepalived 安装和配置

安装 Keepalived

```shell
yum install -y keepalived
```

安装虚拟服务器管理命令

```shell
yum install -y ipvsadm
```

编写 shell 脚本

`/etc/keepalived/chk.sh`

```shell
if [ $(ps -C haproxy --no-header | wc -l) -eq 0 ]; then
       killall keepalived
fi
```

编写 keepalived 配置文件

`/etc/keepalived/keepalived.conf`

```shell
! Configuration File for keepalived
#简单的头部，这里主要可以做邮件通知报警等的设置，此处就暂不配置了；
global_defs {
        #notificationd LVS_DEVEL
}
#预先定义一个脚本，方便后面调用，也可以定义多个，方便选择；
vrrp_script chk_haproxy {
    script "/etc/keepalived/check.sh"
    interval 2  #脚本循环运行间隔
}
#VRRP虚拟路由冗余协议配置
vrrp_instance VI_1 {   #VI_1 是自定义的名称；
    state MASTER    #MASTER表示是一台主设备，BACKUP表示为备用设备【我们这里因为设置为开启不抢占，所以都设置为备用】
    nopreempt      #开启不抢占
    interface ens33   #指定VIP需要绑定的物理网卡
    virtual_router_id 11   #VRID虚拟路由标识，也叫做分组名称，该组内的设备需要相同
    priority 100   #定义这台设备的优先级 1-254；开启了不抢占，所以此处优先级必须高于另一台

    advert_int 1   #生存检测时的组播信息发送间隔，组内一致
    authentication {    #设置验证信息，组内一致
        auth_type PASS   #有PASS 和 AH 两种，常用 PASS
        auth_pass 111111    #密码
    }
    virtual_ipaddress {
        192.168.100.200    #指定VIP地址，组内一致，可以设置多个IP
    }
    track_script {    #使用在这个域中使用预先定义的脚本，上面定义的
        chk_haproxy
    }
}
```

启动 Keepalived

```
systemctl start keepalived
```

测试

![65](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/65.png)

![66](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/66.png)

![67](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/67.png)

# 9. Mycat 企业级运维

## 9.1 Mycat-web 性能监控平台

在现在的企业开发中，作为一个合格的开发人员来说，不仅要完成正常的编码任务，同时也要掌握一定的运维能力。当线上系统出现问题时，要能够快速的将隐藏问题找出来并进行解决。

Mycat-web是mycat的可视化运维监控平台。其能够管理和监控mycat的流量、连接数、线程数、JVM、内存。并且基于内部统计还能够分析出慢SQL与高频SQL。为sql优化提供了重要的依据。

准备

安装 zookeeper

```shell
#创建zk目录
mkdir -p /usr/local/zookeeper

#下载zk安装包
wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gz

#解压
tar -zxvf zookeeper-3.4.9.tar.gz

#进入解压目录
cd zookeeper-3.4.9

#创建数据和日志目录
mkdir data && mkdir logs

#进入 conf 目录
cd conf/

#拷贝配置文件
cp zoo_sample.cfg zoo.cfg
```

配置数据和日志目录的位置

`zoo.cfg`

```properties
# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial 
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between 
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just 
# example sakes.
dataDir=/usr/local/zookeeper/zookeeper-3.4.9/data/
logsDir=/usr/local/zookeeper/zookeeper-3.4.9/logs/
# the port at which the clients will connect
clientPort=2181
```

启动 zkServer.sh

```
./zkServer.sh start
```

安装 Mycat-web

下载

```shell
wget http://dl.mycat.org.cn/mycat-web-1.0/Mycat-web-1.0-SNAPSHOT-20170102153329-linux.tar.gz
```

启动

```
./start.sh
```

访问

```
http://192.168.100.131:8082/mycat/
```

![68](https://raw.githubusercontent.com/Novak666/Learning-working-skill/main/2022.01.18/pics/68.png)

mycat-web的使用非常简单，其内部已经提供了mycat配置、mycat监控、sql监控与sql上线检查。只需要在其内部配置好自己的mycat服务器信息即可完成使用。